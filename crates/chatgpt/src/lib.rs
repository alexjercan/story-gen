use anyhow::Result;
use bevy::tasks::AsyncComputeTaskPool;
use bevy::{prelude::*, tasks::Task};
use futures_lite::future;
use openai_api_rust::chat::*;
use openai_api_rust::*;

// This component is used to run the ChatGPT call on another thread
#[derive(Component)]
struct ChatGPTTask(Task<Result<String>>);

// The plugin will listen for this event to set the openai key
#[derive(Event, Debug)]
pub struct InputApiKeyEvent(pub String);

// The plugin will listen for this event to reset the ChatGPT state
#[derive(Event, Debug)]
pub struct InputSystemEvent(pub String);

// The plugin will listen for this event to trigger the ChatGPT call
#[derive(Event, Debug)]
pub struct InputChatEvent(pub String);

// This event is triggered when a story is generated by ChatGPT
#[derive(Event, Debug)]
pub struct CreatedStoryEvent(pub Result<String>);

// This resource is used to store the ChatGPT request state
#[derive(Resource, Debug, Deref, DerefMut)]
struct StoryChatBody(ChatBody);

// TODO: this is a workaround to be able to clone the ChatBody struct
impl From<&ChatBody> for StoryChatBody {
    fn from(body: &ChatBody) -> Self {
        Self(ChatBody {
            model: body.model.clone(),
            max_tokens: body.max_tokens,
            temperature: body.temperature,
            top_p: body.top_p,
            n: body.n,
            stream: body.stream,
            stop: body.stop.clone(),
            presence_penalty: body.presence_penalty,
            frequency_penalty: body.frequency_penalty,
            logit_bias: body.logit_bias.clone(),
            user: body.user.clone(),
            messages: body.messages.clone(),
        })
    }
}

impl Clone for StoryChatBody {
    fn clone(&self) -> Self {
        Self(ChatBody {
            model: self.model.clone(),
            max_tokens: self.max_tokens,
            temperature: self.temperature,
            top_p: self.top_p,
            n: self.n,
            stream: self.stream,
            stop: self.stop.clone(),
            presence_penalty: self.presence_penalty,
            frequency_penalty: self.frequency_penalty,
            logit_bias: self.logit_bias.clone(),
            user: self.user.clone(),
            messages: self.messages.clone(),
        })
    }
}

impl Default for StoryChatBody {
    fn default() -> Self {
        Self(ChatBody {
            model: "gpt-3.5-turbo".to_string(),
            max_tokens: None,
            temperature: None,
            top_p: None,
            n: None,
            stream: None,
            stop: None,
            presence_penalty: None,
            frequency_penalty: None,
            logit_bias: None,
            user: None,
            messages: Vec::default(),
        })
    }
}

// This resource holds the OpenAI API key
#[derive(Resource, Default, Debug, Deref, DerefMut, Clone)]
struct StoryChatAuth(Option<Auth>);

#[derive(Default)]
pub struct ChatGPTPlugin {
    auth: Option<Auth>,
}

impl ChatGPTPlugin {
    pub fn from_env() -> Self {
        Self {
            auth: Auth::from_env().ok(),
        }
    }
}

impl Plugin for ChatGPTPlugin {
    fn build(&self, app: &mut App) {
        app.add_event::<InputApiKeyEvent>()
            .add_event::<InputSystemEvent>()
            .add_event::<InputChatEvent>()
            .add_event::<CreatedStoryEvent>()
            .insert_resource(StoryChatAuth(self.auth.clone()))
            .init_resource::<StoryChatBody>()
            .add_systems(
                Update,
                (
                    handle_apikey_event,
                    handle_input_system,
                    handle_input_chat,
                    poll_chatgpt_task,
                ),
            );
    }
}

fn handle_apikey_event(
    mut ev_input_apikey: EventReader<InputApiKeyEvent>,
    mut auth: ResMut<StoryChatAuth>,
) {
    ev_input_apikey.iter().for_each(|ev| {
        auth.0 = Some(Auth::new(&ev.0));
    });
}

fn handle_input_system(
    mut ev_input_system: EventReader<InputSystemEvent>,
    mut chat_body: ResMut<StoryChatBody>,
) {
    ev_input_system.iter().for_each(|ev| {
        let message = ev.0.clone();
        chat_body.messages = vec![Message {
            role: Role::System,
            content: message,
        }];
    });
}

fn handle_input_chat(
    mut commands: Commands,
    mut ev_input_chat: EventReader<InputChatEvent>,
    mut chat_body: ResMut<StoryChatBody>,
    auth: Res<StoryChatAuth>,
) {
    ev_input_chat.iter().for_each(|ev| {
        let message = ev.0.clone();
        chat_body.messages.push(Message {
            role: Role::User,
            content: message,
        });

        let auth = auth.clone().0.expect("No OpenAI API key provided");
        let chat_body = chat_body.clone();

        let thread_pool = AsyncComputeTaskPool::get();
        let task = thread_pool.spawn(async move {
            let openai = OpenAI::new(auth, "https://api.openai.com/v1/");

            openai
                .chat_completion_create(&chat_body)
                .map_err(|e| anyhow::anyhow!(e))?
                .choices
                .get(0)
                .ok_or_else(|| anyhow::anyhow!("No choice in response"))?
                .message
                .as_ref()
                .map(|m| m.content.clone())
                .ok_or_else(|| anyhow::anyhow!("No message in response"))
        });

        commands.spawn(ChatGPTTask(task));
    });
}

fn poll_chatgpt_task(
    mut commands: Commands,
    mut tasks: Query<(Entity, &mut ChatGPTTask)>,
    mut chat_body: ResMut<StoryChatBody>,
    mut ev_created_story: EventWriter<CreatedStoryEvent>,
) {
    let Some((entity, mut task)) = tasks.iter_mut().next() else { return };

    if let Some(action) = future::block_on(future::poll_once(&mut task.0)) {
        if let Ok(message) = &action {
            chat_body.messages.push(Message {
                role: Role::User,
                content: message.clone(),
            });
        }

        ev_created_story.send(CreatedStoryEvent(action));

        commands.entity(entity).despawn();
    }
}
